{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhSx1HLx7FM2ZlemGvbzWH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayonaramagalhaes/Trabalho-Final---ML/blob/main/Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub"
      ],
      "metadata": {
        "id": "eJzveIw2rasz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import kagglehub\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Baixar e carregar o dataset\n",
        "path = kagglehub.dataset_download(\"shaunthesheep/microsoft-catsvsdogs-dataset\")\n",
        "\n",
        "# Mostrar o caminho do dataset\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "#Verificar a estrutura do diretório do dataset\n",
        "pet_images_path = os.path.join(path, 'PetImages')\n",
        "\n",
        "# Verificar se o diretório 'PetImages'\n",
        "if os.path.exists(pet_images_path):\n",
        "    print(\"Conteúdo do diretório PetImages:\", os.listdir(pet_images_path))\n",
        "else:\n",
        "    print(\"O diretório PetImages não foi encontrado!\")\n",
        "\n",
        "#Definir o pré-processamento das imagens\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Redimensiona para 224x224\n",
        "    transforms.Grayscale(num_output_channels=3),  # Converte para 3 canais (RGB)\n",
        "    transforms.ToTensor(),  # Converte para tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normaliza com os valores do ImageNet\n",
        "])\n",
        "\n",
        "# Função para verificar se a imagem é válida (ignorar imagens corrompidas)\n",
        "def is_valid_image(image_path):\n",
        "    try:\n",
        "        with Image.open(image_path) as img:\n",
        "            img.verify()  # Tenta verificar a imagem\n",
        "        return True\n",
        "    except (IOError, SyntaxError):\n",
        "        return False\n",
        "\n",
        "# Criar uma classe Dataset personalizada para carregar as imagens\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_paths, labels, transform=None):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Carregar as imagens e filtrar imagens válidas\n",
        "img_paths = []\n",
        "labels = []\n",
        "\n",
        "for folder in os.listdir(pet_images_path):\n",
        "    folder_path = os.path.join(pet_images_path, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        for img_name in os.listdir(folder_path):\n",
        "            img_path = os.path.join(folder_path, img_name)\n",
        "            if is_valid_image(img_path):  # Verifica se a imagem é válida\n",
        "                img_paths.append(img_path)\n",
        "                label = 0 if folder == 'Cat' else 1\n",
        "                labels.append(label)\n",
        "\n",
        "# Criar dataset com imagens válidas\n",
        "dataset = CustomDataset(img_paths, labels, transform)\n",
        "\n",
        "# Dividir as imagens em treino (80%) e teste (20%)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_data, test_data = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# DataLoader para carregar os dados em batches\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "#Carregar o modelo AlexNet pré-treinado\n",
        "model = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Congelar todas as camadas convolucionais, pois queremos apenas treinar a última camada (classificação)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Substituir a camada final de classificação para 2 classes (Cachorro vs Gato)\n",
        "model.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n",
        "\n",
        "# Definir o dispositivo (GPU ou CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Colocar o modelo em modo de treinamento\n",
        "model.train()\n",
        "\n",
        "# Definir a função de perda (cross-entropy) e o otimizador (Adam)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "# Treinamento do modelo com fine-tuning\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for inputs, labels in tqdm(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Move para o dispositivo (GPU ou CPU)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Passar os dados pelo modelo\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Atualizar os parâmetros\n",
        "        optimizer.step()\n",
        "\n",
        "        # Estatísticas\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Armazenar rótulos e previsões para calcular as métricas\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Calcular precisão\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Exibir as métricas a cada época\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
        "\n",
        "#Avaliação do modelo\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Calcular o relatório de classificação\n",
        "report = classification_report(y_true, y_pred, target_names=['Cat', 'Dog'])\n",
        "\n",
        "# Exibir o relatório de classificação\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(report)\n",
        "\n",
        "# Calcular Acurácia\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Acurácia no conjunto de teste: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc99nA6iwcdG",
        "outputId": "b32cea35-e48a-48af-8445-3b56a5600a3c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/shaunthesheep/microsoft-catsvsdogs-dataset/versions/1\n",
            "Conteúdo do diretório PetImages: ['Dog', 'Cat']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 128MB/s]\n",
            "100%|██████████| 625/625 [12:48<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.1917, Accuracy: 92.67%\n",
            "Precision: 0.9267, Recall: 0.9267, F1-Score: 0.9267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 468/625 [09:26<02:52,  1.10s/it]/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n",
            "100%|██████████| 625/625 [12:39<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5, Loss: 0.1804, Accuracy: 93.52%\n",
            "Precision: 0.9352, Recall: 0.9352, F1-Score: 0.9352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 368/625 [07:27<05:21,  1.25s/it]/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n",
            "100%|██████████| 625/625 [12:41<00:00,  1.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5, Loss: 0.1771, Accuracy: 93.95%\n",
            "Precision: 0.9395, Recall: 0.9395, F1-Score: 0.9395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 156/625 [03:10<09:21,  1.20s/it]/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n",
            "100%|██████████| 625/625 [12:40<00:00,  1.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5, Loss: 0.1705, Accuracy: 94.10%\n",
            "Precision: 0.9410, Recall: 0.9410, F1-Score: 0.9410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▊  | 492/625 [09:56<02:55,  1.32s/it]/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n",
            "100%|██████████| 625/625 [12:37<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5, Loss: 0.1718, Accuracy: 94.16%\n",
            "Precision: 0.9416, Recall: 0.9416, F1-Score: 0.9416\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Cat       0.96      0.92      0.94      2466\n",
            "         Dog       0.92      0.96      0.94      2534\n",
            "\n",
            "    accuracy                           0.94      5000\n",
            "   macro avg       0.94      0.94      0.94      5000\n",
            "weighted avg       0.94      0.94      0.94      5000\n",
            "\n",
            "Acurácia no conjunto de teste: 0.9392\n"
          ]
        }
      ]
    }
  ]
}