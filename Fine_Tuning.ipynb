{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOa4DFOsdng2Ur4+Tq9NUvK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayonaramagalhaes/Trabalho-Final---ML/blob/main/Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub\n"
      ],
      "metadata": {
        "id": "n39Jb-k-E1vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import kagglehub\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#Baixar e carregar o dataset\n",
        "path = kagglehub.dataset_download(\"shaunthesheep/microsoft-catsvsdogs-dataset\")\n",
        "\n",
        "# Mostrar o caminho do dataset\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "#Verificar o dataset\n",
        "pet_images_path = os.path.join(path, 'PetImages')\n",
        "\n",
        "# Verificar o 'PetImages'\n",
        "if os.path.exists(pet_images_path):\n",
        "    print(\"Conteúdo do diretório PetImages:\", os.listdir(pet_images_path))\n",
        "else:\n",
        "    print(\"O diretório PetImages não foi encontrado!\")\n",
        "\n",
        "#pré-processamento das imagens\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Redimensiona para 224x224\n",
        "    transforms.Grayscale(num_output_channels=3),  # Converte para 3 canais (RGB)\n",
        "    transforms.ToTensor(),  # Converte para tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normaliza com os valores do ImageNet\n",
        "])\n",
        "\n",
        "# Função para verificar se a imagem é válida (ignorar imagens corrompidas)\n",
        "def is_valid_image(image_path):\n",
        "    try:\n",
        "        with Image.open(image_path) as img:\n",
        "            img.verify()\n",
        "        return True\n",
        "    except (IOError, SyntaxError):\n",
        "        return False\n",
        "\n",
        "# Criar uma classe Dataset p carregar as imagens\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_paths, labels, transform=None):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Carregar as imagens e filtrar imagens válidas\n",
        "img_paths = []\n",
        "labels = []\n",
        "\n",
        "for folder in os.listdir(pet_images_path):\n",
        "    folder_path = os.path.join(pet_images_path, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        for img_name in os.listdir(folder_path):\n",
        "            img_path = os.path.join(folder_path, img_name)\n",
        "            if is_valid_image(img_path):\n",
        "                img_paths.append(img_path)\n",
        "                label = 0 if folder == 'Cat' else 1\n",
        "                labels.append(label)\n",
        "\n",
        "# Criar dataset com imagens válidas\n",
        "dataset = CustomDataset(img_paths, labels, transform)\n",
        "\n",
        "#treino (80%) e teste (20%)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_data, test_data = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# DataLoader para carregar os dados em batches\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "#Carregar o modelo AlexNet pré-treinado\n",
        "model = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Congelar todas as camadas convolucionais,treinar a última camada classificação\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Substituir a camada final de classificação para 2 classes (Cachorro vs Gato)\n",
        "model.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Colocar o modelo em modo de treinamento\n",
        "model.train()\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "# Treinamento do modelo com fine-tuning\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for inputs, labels in tqdm(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Move para o dispositivo (GPU ou CPU)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Passar os dados pelo modelo\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Atualizar os parâmetros\n",
        "        optimizer.step()\n",
        "\n",
        "        # Estatísticas\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Armazenar rótulos e previsões para calcular as métricas\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Calcular precisão\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Exibir as métricas a cada época\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
        "\n",
        "#Avaliação do modelo\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Calcular o relatório de classificação\n",
        "report = classification_report(y_true, y_pred, target_names=['Cat', 'Dog'])\n",
        "\n",
        "# Exibir o relatório de classificação\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(report)\n",
        "\n",
        "# Calcular Acurácia\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Acurácia no conjunto de teste: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "er7d7aNKE1-u",
        "outputId": "e994bc82-ef73-426f-a28e-88258b73b1b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/shaunthesheep/microsoft-catsvsdogs-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 788M/788M [00:06<00:00, 118MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/shaunthesheep/microsoft-catsvsdogs-dataset/versions/1\n",
            "Conteúdo do diretório PetImages: ['Dog', 'Cat']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 150MB/s]\n",
            "100%|██████████| 625/625 [12:17<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.1975, Accuracy: 92.47%\n",
            "Precision: 0.9247, Recall: 0.9247, F1-Score: 0.9247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [12:10<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5, Loss: 0.1758, Accuracy: 93.63%\n",
            "Precision: 0.9363, Recall: 0.9363, F1-Score: 0.9363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [12:10<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5, Loss: 0.1768, Accuracy: 93.78%\n",
            "Precision: 0.9378, Recall: 0.9378, F1-Score: 0.9378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [12:10<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5, Loss: 0.1733, Accuracy: 94.12%\n",
            "Precision: 0.9412, Recall: 0.9412, F1-Score: 0.9412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [12:09<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5, Loss: 0.1762, Accuracy: 94.01%\n",
            "Precision: 0.9401, Recall: 0.9401, F1-Score: 0.9401\n",
            "\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Cat       0.92      0.97      0.94      2447\n",
            "         Dog       0.97      0.92      0.94      2553\n",
            "\n",
            "    accuracy                           0.94      5000\n",
            "   macro avg       0.94      0.94      0.94      5000\n",
            "weighted avg       0.94      0.94      0.94      5000\n",
            "\n",
            "Acurácia no conjunto de teste: 0.9432\n"
          ]
        }
      ]
    }
  ]
}